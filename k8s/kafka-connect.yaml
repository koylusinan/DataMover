# =============================================
# Kafka + Kafka Connect (Debezium) for Kubernetes
# Created: 2024-11-26
# Worker Specs: 16 Core CPU, 32GB Memory
# =============================================
# Uygulama:
#   1. Worker node'da dizin oluştur:
#      ssh hp-devops-k8s-as-pw-01 "sudo mkdir -p /opt/kafka/broker-0 && sudo chmod 777 /opt/kafka/broker-0"
#   2. JMX agent kopyala:
#      ssh hp-devops-k8s-as-pw-XX "sudo mkdir -p /opt/debezium-plugins/jmx-agent"
#      scp jmx_prometheus_javaagent-0.17.2.jar config.yml hp-devops-k8s-as-pw-XX:/opt/debezium-plugins/jmx-agent/
#   3. kubectl apply -f k8s/kafka-connect.yaml
#   4. kubectl get pods -n kafka-connect -w
# =============================================

# ---------------------------------------------
# NAMESPACE
# ---------------------------------------------
apiVersion: v1
kind: Namespace
metadata:
  name: kafka-connect
  labels:
    app.kubernetes.io/name: kafka-connect
    app.kubernetes.io/component: messaging

---
# ---------------------------------------------
# STORAGE CLASS (Local Storage)
# ---------------------------------------------
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: kafka-local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain

---
# ---------------------------------------------
# PERSISTENT VOLUME (Kafka Data)
# ---------------------------------------------
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-kafka-broker-0
  labels:
    type: local
    app: kafka
spec:
  capacity:
    storage: 50Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  storageClassName: kafka-local-storage
  persistentVolumeReclaimPolicy: Retain
  local:
    path: /opt/kafka/broker-0
  nodeAffinity:
    required:
      nodeSelectorTerms:
        - matchExpressions:
            - key: kubernetes.io/hostname
              operator: In
              values:
                - hp-devops-k8s-as-pw-01

---
# ---------------------------------------------
# PERSISTENT VOLUME CLAIM (Kafka Data)
# ---------------------------------------------
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kafka-data-pvc
  namespace: kafka-connect
  labels:
    app: kafka
spec:
  storageClassName: kafka-local-storage
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  selector:
    matchLabels:
      type: local
      app: kafka

---
# ---------------------------------------------
# KAFKA HEADLESS SERVICE (StatefulSet için)
# ---------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  namespace: kafka-connect
  labels:
    app: kafka
spec:
  clusterIP: None
  selector:
    app: kafka
  ports:
    - name: plaintext
      port: 9092
      targetPort: 9092
    - name: controller
      port: 9093
      targetPort: 9093

---
# ---------------------------------------------
# KAFKA SERVICE (ClusterIP)
# ---------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: kafka-connect
  labels:
    app: kafka
spec:
  type: ClusterIP
  selector:
    app: kafka
  ports:
    - name: plaintext
      port: 9092
      targetPort: 9092
    - name: controller
      port: 9093
      targetPort: 9093

---
# ---------------------------------------------
# KAFKA STATEFULSET (KRaft Mode - Confluent)
# ---------------------------------------------
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: kafka-connect
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      nodeSelector:
        kubernetes.io/hostname: hp-devops-k8s-as-pw-01

      initContainers:
        - name: init-kafka-dir
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              mkdir -p /var/lib/kafka/data
              chown -R 1000:1000 /var/lib/kafka/data
              rm -rf /var/lib/kafka/data/*
              echo "Kafka data directory initialized and cleaned"
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data

      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          command:
            - sh
            - -c
            - |
              # Generate server.properties
              cat > /tmp/server.properties << 'EOF'
              node.id=1
              process.roles=broker,controller
              controller.quorum.voters=1@localhost:9093
              controller.listener.names=CONTROLLER
              listeners=PLAINTEXT://:9092,CONTROLLER://:9093
              advertised.listeners=PLAINTEXT://10.233.60.70:9092
              listener.security.protocol.map=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
              inter.broker.listener.name=PLAINTEXT
              log.dirs=/var/lib/kafka/data
              offsets.topic.replication.factor=1
              transaction.state.log.replication.factor=1
              transaction.state.log.min.isr=1
              group.initial.rebalance.delay.ms=0
              num.partitions=3
              num.io.threads=8
              num.network.threads=3
              auto.create.topics.enable=false
              delete.topic.enable=true
              EOF

              # Format storage if needed
              if [ ! -f /var/lib/kafka/data/meta.properties ]; then
                echo "Formatting KRaft storage..."
                kafka-storage format -t MkU3OEVBNTcwNTJENDM2Qk -c /tmp/server.properties --ignore-formatted
              fi

              # Start Kafka
              echo "Starting Kafka..."
              exec kafka-server-start /tmp/server.properties
          ports:
            - name: plaintext
              containerPort: 9092
            - name: controller
              containerPort: 9093
          env:
            - name: KAFKA_HEAP_OPTS
              value: "-Xms6G -Xmx10G"
          resources:
            requests:
              memory: "8Gi"
              cpu: "2000m"
            limits:
              memory: "14Gi"
              cpu: "6000m"
          readinessProbe:
            tcpSocket:
              port: 9092
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
          livenessProbe:
            tcpSocket:
              port: 9092
            initialDelaySeconds: 60
            periodSeconds: 20
            timeoutSeconds: 5
            failureThreshold: 3
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data

      volumes:
        - name: kafka-data
          persistentVolumeClaim:
            claimName: kafka-data-pvc

---
# ---------------------------------------------
# KAFKA CONNECT SERVICE
# ---------------------------------------------
apiVersion: v1
kind: Service
metadata:
  name: kafka-connect
  namespace: kafka-connect
  labels:
    app: kafka-connect
spec:
  type: ClusterIP
  selector:
    app: kafka-connect
  ports:
    - name: rest
      port: 8083
      targetPort: 8083
    - name: jmx
      port: 9097
      targetPort: 9097

---
# ---------------------------------------------
# KAFKA CONNECT DEPLOYMENT (Debezium)
# ---------------------------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kafka-connect
  namespace: kafka-connect
  labels:
    app: kafka-connect
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kafka-connect
  template:
    metadata:
      labels:
        app: kafka-connect
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app: kafka-connect

      initContainers:
        # Kafka'nın hazır olmasını bekle (Service IP ile)
        - name: wait-for-kafka
          image: alpine:3.20
          command:
            - sh
            - -c
            - |
              echo "Waiting for Kafka to be ready..."
              apk add --no-cache netcat-openbsd > /dev/null 2>&1
              KAFKA_IP="10.233.60.70"
              until nc -z -w2 $KAFKA_IP 9092; do
                echo "Kafka not ready yet at $KAFKA_IP:9092, retrying in 5s..."
                sleep 5
              done
              echo "Kafka is ready at $KAFKA_IP:9092!"
          resources:
            requests:
              memory: "32Mi"
              cpu: "50m"
            limits:
              memory: "64Mi"
              cpu: "100m"

        # Connect internal topic'lerini compact policy ile oluştur
        - name: create-connect-topics
          image: confluentinc/cp-kafka:7.5.0
          command:
            - sh
            - -c
            - |
              KAFKA_IP="10.233.60.70"
              echo "Creating Kafka Connect internal topics with compact cleanup policy..."

              # Delete existing topics if they exist (cleanup)
              echo "Deleting existing topics if any..."
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --delete --topic connect-offsets --if-exists 2>/dev/null || true
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --delete --topic connect-configs --if-exists 2>/dev/null || true
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --delete --topic connect-status --if-exists 2>/dev/null || true

              # Wait for deletion to complete
              sleep 5

              # Create topics with compact cleanup policy
              echo "Creating connect-offsets topic (25 partitions, compact)..."
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --create --topic connect-offsets \
                --partitions 25 --replication-factor 1 --config cleanup.policy=compact --if-not-exists

              echo "Creating connect-configs topic (1 partition, compact)..."
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --create --topic connect-configs \
                --partitions 1 --replication-factor 1 --config cleanup.policy=compact --if-not-exists

              echo "Creating connect-status topic (5 partitions, compact)..."
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --create --topic connect-status \
                --partitions 5 --replication-factor 1 --config cleanup.policy=compact --if-not-exists

              # Verify topics
              echo "Verifying topics..."
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --describe --topic connect-offsets
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --describe --topic connect-configs
              kafka-topics --bootstrap-server $KAFKA_IP:9092 --describe --topic connect-status

              echo "Topics created successfully!"
          resources:
            requests:
              memory: "256Mi"
              cpu: "100m"
            limits:
              memory: "512Mi"
              cpu: "500m"

      containers:
        - name: kafka-connect
          image: quay.io/debezium/connect:3.0.2.Final
          ports:
            - name: rest
              containerPort: 8083
            - name: jmx
              containerPort: 9097
          env:
            - name: BOOTSTRAP_SERVERS
              value: "10.233.60.70:9092"
            - name: GROUP_ID
              value: "connect-cluster"
            - name: CONFIG_STORAGE_TOPIC
              value: "connect-configs"
            - name: OFFSET_STORAGE_TOPIC
              value: "connect-offsets"
            - name: STATUS_STORAGE_TOPIC
              value: "connect-status"
            - name: CONFIG_STORAGE_REPLICATION_FACTOR
              value: "1"
            - name: OFFSET_STORAGE_REPLICATION_FACTOR
              value: "1"
            - name: STATUS_STORAGE_REPLICATION_FACTOR
              value: "1"
            - name: KEY_CONVERTER
              value: "org.apache.kafka.connect.json.JsonConverter"
            - name: VALUE_CONVERTER
              value: "org.apache.kafka.connect.json.JsonConverter"
            - name: KEY_CONVERTER_SCHEMAS_ENABLE
              value: "false"
            - name: VALUE_CONVERTER_SCHEMAS_ENABLE
              value: "false"
            # REST API configuration
            - name: REST_ADVERTISED_HOST_NAME
              value: "kafka-connect"
            - name: REST_LISTENERS
              value: "http://0.0.0.0:8083"
            # Plugin path (both default and custom plugins)
            - name: CONNECT_PLUGIN_PATH
              value: "/kafka/connect,/kafka/connect/plugins"
            # JMX and Prometheus metrics
            - name: JMXHOST
              value: "localhost"
            - name: AUTO_INCLUDE_JMX_REPORTER
              value: "false"
            - name: KAFKA_OPTS
              value: |-
                -javaagent:/kafka/connect/plugins/jmx-agent/jmx_prometheus_javaagent-0.17.2.jar=9097:/kafka/connect/plugins/jmx-agent/config.yml
                -Ddebezium.metrics.unregistration.on.stop=true
                -Ddebezium.metrics.scope=per-connector
                -Ddebezium.metrics.mbean.domain=debezium-kafka-connect
                -Dcom.sun.management.jmxremote
                -Dcom.sun.management.jmxremote.authenticate=false
                -Dcom.sun.management.jmxremote.ssl=false
                -Djava.rmi.server.hostname=kafka-connect
                -Djava.rmi.server.port=9097
            # Memory settings (optimized for 32GB worker nodes)
            - name: KAFKA_HEAP_OPTS
              value: "-Xms2G -Xmx8G"
          resources:
            requests:
              memory: "4Gi"
              cpu: "2000m"
            limits:
              memory: "12Gi"
              cpu: "8000m"
          readinessProbe:
            httpGet:
              path: /connectors
              port: 8083
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 6
          livenessProbe:
            httpGet:
              path: /connectors
              port: 8083
            initialDelaySeconds: 90
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          volumeMounts:
            - name: jmx-agent
              mountPath: /kafka/connect/plugins/jmx-agent

      volumes:
        - name: jmx-agent
          hostPath:
            path: /opt/debezium-plugins/jmx-agent
            type: DirectoryOrCreate
